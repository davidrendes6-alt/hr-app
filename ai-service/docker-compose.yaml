services:
  ai-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hr-ai-service
    ports:
      - "8003:8003"
    environment:
      - SPRING_APPLICATION_NAME=ai-service
      - SERVER_PORT=8003
      - HUGGINGFACE_API_URL=https://api-inference.huggingface.co/models
      - HUGGINGFACE_API_MODEL=google/flan-t5-base
      - HUGGINGFACE_API_TIMEOUT=30000
    networks:
      - hr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8003/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  hr-network:
    driver: bridge

