services:
  ai-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hr-ai-service
    ports:
      - "8003:8003"
    environment:
      - SPRING_APPLICATION_NAME=ai-service
      - SERVER_PORT=8003
      - HUGGINGFACE_API_URL=https://router.huggingface.co/v1/chat/completions
      - HUGGINGFACE_API_MODEL=meta-llama/Llama-3.1-8B-Instruct
      - HUGGINGFACE_API_TOKEN=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
    networks:
      - hr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8003/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  hr-network:
    driver: bridge

